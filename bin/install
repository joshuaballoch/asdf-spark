#!/usr/bin/env bash

install_spark() {
  local version=$1
  local install_path=$2

  if [ "$TMPDIR" = "" ]; then
    local tmp_download_dir=$(mktemp -d -t spark_build_XXXXXX)
  else
    local tmp_download_dir=$TMPDIR
  fi

  # path to the tar file
  local source_path=$(get_download_file_path $version $tmp_download_dir)
  echo $source_path
  download_source_file $version $source_path


  # running this in a subshell
  # we don't want to disturb current working dir
  (
    tar -xvf $source_path -C $install_path --strip-components=1 || exit 1
  )
}


download_source_file() {
  local version=$1
  local download_path=$2
  local download_url=$(get_download_url $version)
  echo $download_url

  curl -Lo $download_path -C - $download_url
}


get_download_file_path() {
  local version=$1
  local tmp_download_dir=$2

  local pkg_name="spark-${version}-bin-hadoop2.7.tgz"

  echo "$tmp_download_dir/$pkg_name"
}


get_download_url() {
  local version=$1

  echo "http://apache.claz.org/spark/spark-${version}/spark-${version}-bin-hadoop2.7.tgz"
}


install_spark $ASDF_INSTALL_VERSION $ASDF_INSTALL_PATH
